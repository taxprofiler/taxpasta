---
title: "Tutorial"
author: "James A. Fellows Yates"
format: html
---

## Introduction

This tutorial will show you how to generate standardised taxonomic profiles from the heterogeneous output of two popular taxonomic profilers: [`Kraken2`](https://ccb.jhu.edu/software/kraken2/) and [`mOTUs`](https://motu-tool.org/), and then demonstrate some of the benefits of this standardisation when running downstream analyses on such tables in the popular data science programming language [`R`](https://www.r-project.org/).

## Preparation

For this tutorial you will need an internet connection, `taxpasta` already [installed](/index), and  R with the `readr` package from the [Tidyverse](https://tidyverse.org) set of packages installed, and a UNIX based operating system (Linux, OSX or Windows Subsystem for Linux).

First we will make a 'scratch' directory where we can run all the tutorial and delete the files after.

```{bash}
mkdir taxpasta-tutorial
```

We will also need to download some example taxonomic profiles from `Kraken2` and `mOTUs`. If you're on UNIX a machine we can download some test data from the taxpasta repository.

```{bash}
## mOTUs
curl https://github.com/taxprofiler/taxpasta/raw/dev/tests/data/motus/2612_pe-ERR5766176-db_mOTU.out -o taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out
curl https://github.com/taxprofiler/taxpasta/raw/dev/tests/data/motus/2612_se-ERR5766180-db_mOTU.out -o taxpasta-tutorial/2612_se-ERR5766180-db_mOTU.out

## Kraken2
curl https://github.com/taxprofiler/taxpasta/raw/dev/tests/data/kraken2/2612_pe-ERR5766176-db1.kraken2.report.txt -o taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt
```

## Tutorial

To begin, we can try loading a `mOTUs` profile into R using a common and 'default' table reading command, `read_tsv()` from the `readr` package.

```{r}
library(readr)

profile_motus_2612_pe <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out")
```

You can see we immediately hit an error, as there is a 'comment' line at the top of the profile with information on how the profile was generated.

While this is very nice for reproducibility, to load this we have to instead add extra options to the function, which makes loading the table less than smooth for downstream analyses.

```{r}
profile_motus_2612_pe <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out", comment = "#")
```

However, once again we hit another error - the column headers are _also_ specified as a comment line...

Instead we can try to skip the first two tool information lines

```{r}
profile_motus_2612_pe <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out", skip = 2)

profile_motus_2612_pe 
```

This now works! However we argue getting this to work takes much too effort to simply load what is essentially a simple table.

Furthermore, we would have to load each profile one by one for each sample, requiring more complicated loops and table join code.

Now lets try loading the `Kraken2` output.

```{r}
profile_kraken2_2612_pe <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt")
profile_kraken2_2612_pe
```
 
 This doesn't fail to load, but unfortunately the column headers look a bit wierd... it seems the Kraken2 'table' file does not include a column header! In this case we have to specify these ourselves..

```{r}
profile_kraken2_2612_pe <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt", col_names = c("percent", "clade_assigned_reads", "direct_assigned_reads", "taxonomy_lvl", "taxonomid_id", "name"))
profile_kraken2_2612_pe
```

This looks better, but if we see the [Kraken2 documentation](https://github.com/DerrickWood/kraken2/wiki/Manual#distinct-minimizer-count-information) we can also see that sometimes _extra_ columns can be added when certain flags are given, meaning that our column names wouldn't always work.

So again, not trivial.

But this is where `taxpasta` comes to the rescue!

> ⚠️  xxxx something about losing information

With `taxpasta`, we can already standardised and make multi-sample taxon tables for you at the command line level (e.g., immediately after profiling), rather than having to do this with custom scripts and a lot of manual munging.

If you want to standardise a single sample, you just need to specify the profiler of the input file, the output file name (with a valid suffix, which will tell `taxpasta` which format to save the output), and finally the the profile itself. 

```{bash}
source ~/.bashrc
conda activate taxpasta
```

```{bash}
taxpasta standardise --profiler kraken2 -o 2612_pe-ERR5766176-db1_kraken2.tsv taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt
```

Now lets try to load the `Kraken2` result into `R` again...

```{r}
profile_kraken2_2612_pe <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db1_kraken2.tsv")
profile_kraken2_2612_pe
```

You can see we did not have to specify any additional column names or other loading parameters, `taxpasta` has done it for you.

But what about the more complicated `mOTUs` case, where we have unusual comment headers, and also multiple samples?

In this case we can instead use `taxpasta merge`, which will both standardise _and_ stick the profiles of different samples into one for you - again all the command line. Once again, we just need to specify the profiler, the output name and format (via the suffix), and the profile itself.

```{bash}
taxpasta merge --profiler motus -o taxpasta-tutorial/dbMOTUs_motus.tsv taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out taxpasta-tutorial/2612_se-ERR5766180-db_mOTU.out
```
