---
format: gfm
---

# General Tutorial

## Introduction

This tutorial will show you how to generate standardised taxonomic profiles from the heterogeneous output of two popular taxonomic classifiers/profilers: [`Kraken2`](https://ccb.jhu.edu/software/kraken2/) and [`mOTUs`](https://motu-tool.org/), and then demonstrate some of the benefits of this standardisation when running downstream analyses on such tables in the popular data science programming language [`R`](https://www.r-project.org/).

## Preparation

### Software

For this tutorial you will need an internet connection, `taxpasta` already [installed](/index), and  R with the `readr` and `dplyr` packages from the [Tidyverse](https://tidyverse.org) set of packages installed, and a UNIX based operating system (Linux, OSX or Windows Subsystem for Linux).

To summarise you will need:

- Unix terminal (e.g. `bash`)
- `taxpasta`
- `R`
  - `readr` package
  - `dplyr` package

### Data

First we will make a 'scratch' directory where we can run all the tutorial and delete the files after.

```{bash}
mkdir taxpasta-tutorial
```


We will also need to download some example taxonomic profiles from `Kraken2` and `mOTUs`. If you're on UNIX a machine we can download some test data from the taxpasta repository.

```{bash}
## mOTUs
curl -o taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out https://raw.githubusercontent.com/taxprofiler/taxpasta/dev/tests/data/motus/2612_pe-ERR5766176-db_mOTU.out
curl -o taxpasta-tutorial/2612_se-ERR5766180-db_mOTU.out https://raw.githubusercontent.com/taxprofiler/taxpasta/dev/tests/data/motus/2612_se-ERR5766180-db_mOTU.out

## Kraken2
curl -o taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt https://raw.githubusercontent.com/taxprofiler/taxpasta/dev/tests/data/kraken2/2612_pe-ERR5766176-db1.kraken2.report.txt
```

We should now see three files with contents in the `taxpasta-tutorial` directory

```{bash}
ls -l taxpasta-tutorial/*
```

## Tutorial

### Raw classifer output

To begin, let's look at the contents of the output from each of the classifiers/profilers.

For `mOTUs`:

```bash
head taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out
```

and `Kraken2`:

```bash
head taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt
```

These look quite different, and neither are in a nice "pure" tabular formats that data scientists and analysis software normally like. They also have different types columns, and in the case of `Kraken2` has an interesting "indentation" way of showing the taxonomic rank of each hit.

We can try loading a `mOTUs` profile into R using a common and "default" table reading command, `read_tsv()` from the `readr` package.

```{r}
library(readr)

profile_motus_2612_pe_raw <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out")
```

You can see we immediately hit an error, as there is a 'comment' line at the top of the profile with information on how the profile was generated.

While this is very nice for reproducibility, to load this we have to instead add extra options to the function, which makes loading the table less than smooth for downstream analyses.

```{r}
profile_motus_2612_pe_raw <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out", comment = "#")
```

However, once again we hit another error - the column headers are _also_ specified as a comment line...

Instead we can try to skip the first two tool information lines

```{r}
profile_motus_2612_pe_raw <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out", skip = 2)

profile_motus_2612_pe_raw
```

This now works! However getting this to work takes too much effort to simply load what is essentially a simple table.

Furthermore, we would have to load each profile one by one for each sample, requiring more complicated loops and table join code.

Now let's try loading the `Kraken2` output.

```{r}
profile_kraken2_2612_pe_raw <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt")
profile_kraken2_2612_pe_raw
```

This doesn't fail to load, but unfortunately the column headers look a bit weird. It seems the Kraken2 'table' file does not include a column header! In this case we have to specify these ourselves...

```{r}
profile_kraken2_2612_pe_raw <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt", col_names = c("percent", "clade_assigned_reads", "direct_assigned_reads", "taxonomy_lvl", "taxonomy_id", "name"))
profile_kraken2_2612_pe_raw
```

This looks better, but if we see the [Kraken2 documentation](https://github.com/DerrickWood/kraken2/wiki/Manual#distinct-minimizer-count-information) we can also see that sometimes _extra_ columns can be added when certain flags are given, meaning that our column names wouldn't always work.

So again, not trivial.

### Comparing raw output of different classifiers

What if we wanted to compare the output of the different tools? A nice way to do this would be to merge the files into one table.

In the tidyverse flavour of R, we would do this with the `full_join` function of the `dplyr` package.

```{r, error=TRUE}
library(dplyr)
full_join(profile_motus_2612_pe_raw, profile_kraken2_2612_pe_raw)
```

The error `by must be supplied when x and y have no common variables.` is because the column names are not the same between the two tables for the different classifer's outputs.

```{r}
raw_merged_table <- full_join(profile_motus_2612_pe_raw, profile_kraken2_2612_pe_raw, by = c("NCBI_tax_id" = "taxonomy_id"))
raw_merged_table
```

But wait, this doesn't look right at all. We know which sample column we have from `mOTUs`, but what about the `Kraken` read count column? Also many of the columns of the profiles are _not_ shared between the two classifiers/profilers (see an important note about this [here](#important-caveat)), so we have a lot of "cruft", and really the resulting file makes no sense, as you can't do any proper comparison.

### taxpasta standardise

But this is where `taxpasta` comes to the rescue!

With `taxpasta`, we can already standardised and make multi-sample taxon tables for you at the command-line level (e.g., immediately after classification/profiling), rather than having to do this with custom scripts and a lot of manual munging.

If you want to standardise a single sample, you just need to specify the classifier/profiler of the input file, the output file name (with a valid suffix, which will tell `taxpasta` which format to save the output), and finally the profile itself.

```{bash}
taxpasta standardise --profiler kraken2 -o taxpasta-tutorial/2612_pe-ERR5766176-db1_kraken2.tsv taxpasta-tutorial/2612_pe-ERR5766176-db1.kraken2.report.txt
```

Let's look at what the resulting looks like

```{bash}
head taxpasta-tutorial/2612_pe-ERR5766176-db1_kraken2.tsv
```

This looks much more tabular!

Now let's try to load the `taxpasta` standardised `Kraken2` result into `R` again...

```{r}
profile_kraken2_2612_pe_standardised <- read_tsv("taxpasta-tutorial/2612_pe-ERR5766176-db1_kraken2.tsv")
profile_kraken2_2612_pe_standardised
```

You can see we did not have to specify any additional column names or other loading parameters, `taxpasta` has done it for you.

### taxpasta merge

But what about the more complicated `mOTUs` case, where we have unusual comment headers, but also like in this tutorial when we have profiles from multiple _samples_ to be standardised?

In this case we can instead use `taxpasta merge`, which will both standardise _and_ stick the profiles of different samples into one for you - again all through the command-line. Once again, we just need to specify the classifer/profiler, the output name and format (via the suffix), and the profile itself.

```{bash}
taxpasta merge --profiler motus -o taxpasta-tutorial/dbMOTUs_motus.tsv taxpasta-tutorial/2612_pe-ERR5766176-db_mOTU.out taxpasta-tutorial/2612_se-ERR5766180-db_mOTU.out
```

And the result...

```{bash}
head taxpasta-tutorial/dbMOTUs_motus.tsv
```

As with Kraken2, this looks much more tabular and also we can see references to _both_ input files.

Once again, let's try loading the `taxpasta` standardised and merged `mOTUs` result into `R` again...

```{r}
profile_motus_standardised <- read_tsv("taxpasta-tutorial/dbMOTUs_motus.tsv")
profile_motus_standardised
```

You can see here now we have one `taxonomy_id` column, and two columns each referring to each of the samples - and all without having to spend time playing with different parameters and arguments for loading the files.

By default `taxpasta` uses taxonomy IDs to merge tables. If you're interested in having human-readable taxon names see [below](#adding-taxon-names).

### Comparing standardised output of different classifiers

<!-- TODO UPDATE AFTER COLUM NNAME BUG FIX FOR STANDARDISE OLUMN EADER-->

We can also now more easily merge the tables across the two classifiers/profilers, again with the join function - but without any extra specifications, as all the standardised taxonomic tables now share common column header names.

```{r}
standardised_merged_table <- full_join(profile_motus_standardised, profile_kraken2_2612_pe_standardised)
standardised_merged_table
```

### Important caveat

You may have noticed that when 'standardising' the output from each classifier, that not all columns are retained. This is because eachclassifier/ has a different way of making taxonomic classification/profiing, and will produce additional metrics (represented as additional columns) that allow for better evaluation of the accuracy or confidence in each hit.

However, as these metrics are _not_ consistent between eachclassifier/, they are are not comparable between each other, thus in `taxpasta` we only retain columns that are conceptually comparable - i.e., raw read counts.

However you must be aware that _raw read counts_ may not always be an accurate representation of a metagenomic _profile_ where an abundance estimate is mathematically made.

So please be aware that while `taxpasta` is a utility to make comparison between classifiers/profilers easier to be performed, this does not necessarily mean all comparisons are necessarily valid - this will depend on a case-by-case basis of your project!

For example, for simple presence-and-absence analyses (such as pathogen screening), taxpasta will be highly suitable for comparing sensitivity of different tools/databases (providing downstream genomic-level analyses are carried out to confirm the hit). However using the output from taxpasta won't be immediately suitable for differential abundance analysis in microbial ecology without further conversion of the raw-read counts to abundance estimates.

## Clean Up

Once you're happy you've completed the tutorial you can clean up your workspace by simply running

```{bash}
rm -r taxpasta-tutorial
```


